# Cortex Linux Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# API Provider Selection
# =============================================================================
# Choose your AI provider: claude, openai, or ollama
# Default: ollama (free, local inference)
CORTEX_PROVIDER=ollama

# =============================================================================
# Claude API (Anthropic)
# =============================================================================
# Get your API key from: https://console.anthropic.com
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# =============================================================================
# OpenAI API
# =============================================================================
# Get your API key from: https://platform.openai.com
# OPENAI_API_KEY=sk-your-key-here

# =============================================================================
# Kimi K2 API (Moonshot)
# =============================================================================
# Get your API key from: https://platform.moonshot.cn
# MOONSHOT_API_KEY=your-key-here

# =============================================================================
# Ollama (Local LLM) - FREE!
# =============================================================================
# No API key required - runs locally on your machine
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Or run: python scripts/setup_ollama.py

# Ollama base URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (options: llama3.2, llama3.1:8b, mistral, codellama:7b, phi3)
OLLAMA_MODEL=llama3.2

# =============================================================================
# Usage Notes
# =============================================================================
# 
# Quick Start with Ollama (Free):
#   1. Run: python scripts/setup_ollama.py
#   2. Set CORTEX_PROVIDER=ollama (already done above)
#   3. Test: cortex install nginx --dry-run
#
# Using Cloud APIs (Paid):
#   1. Get an API key from Anthropic or OpenAI
#   2. Uncomment and set ANTHROPIC_API_KEY or OPENAI_API_KEY above
#   3. Set CORTEX_PROVIDER=claude or CORTEX_PROVIDER=openai
#   4. Test: cortex install nginx --dry-run
#
# Priority Order:
#   - .env file in current directory (highest)
#   - ~/.cortex/.env
#   - /etc/cortex/.env (Linux only)
#
